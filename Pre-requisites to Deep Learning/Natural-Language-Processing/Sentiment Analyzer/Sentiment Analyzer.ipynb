{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "sentiment = how positive or negative some text is.\n",
    "\n",
    "These are Amazon reviews come with 5 star ratings and we will look at the electronics category. This data comes from this link-\n",
    "http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html (it has multidomain data)\n",
    "\n",
    "The data is already labeled for us-\n",
    "\n",
    "negative.review.txt\n",
    "\n",
    "positive.review.txt\n",
    "\n",
    "This is an XML file, so we will need an XML parser (BeautifulSoup). We will ignore all the extra data and only look at the \"review_text\". To get our feature data, we will count the number of occurances of each word, and divide it by total no. of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer() # it turns words into their base forms, i.e. it makes 'cat' and 'cats' both as 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))  # read the words from the stopword.txt and strips of the space on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open('positive.review.txt').read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_reviews = positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\n",
       " \n",
       " I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
       " \n",
       " As always, Amazon had it to me in &lt;2 business days\n",
       " </review_text>, <review_text>\n",
       " I ordered 3 APC Back-UPS ES 500s on the recommendation of an employee of mine who used to work at APC. I've had them for about a month now without any problems. They've functioned properly through a few unexpected power interruptions. I'll gladly order more if the need arises.\n",
       " \n",
       " Pros:\n",
       "  - Large plug spacing, good for power adapters\n",
       "  - Simple design\n",
       "  - Long cord\n",
       " \n",
       " Cons:\n",
       "  - No line conditioning (usually an expensive option\n",
       " </review_text>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_reviews = BeautifulSoup(open('negative.review.txt').read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " cons\n",
       " tips extremely easy on carpet and if you have a lot of cds stacked at the top\n",
       " \n",
       " poorly designed, it is a vertical cd rack that doesnt have individual slots for cds, so if you want a cd from the bottom of a stack you have basically pull the whole stack to get to it\n",
       " \n",
       " putting it together was a pain, the one i bought i had to break a piece of metal just to fit it in its guide holes.\n",
       " \n",
       " again..poorly designed... doesnt even fit cds that well, there are gaps, and the cd casses are loose fitting\n",
       " \n",
       " pros\n",
       " ..........\n",
       " i guess it can hold a lot of cds....\n",
       " </review_text>, <review_text>\n",
       " It's a nice look, but it tips over very easily. It is not steady on a rug surface dispite what the picture on the box shows. My advice is if you need a CD rack that holds a lot of CD's? Save your money and invest in something nicer and more sturdy\n",
       " </review_text>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So, the number of both positive and the negative reviews are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)  # tokenize the words (splits the word based on space as a delimiter)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # only take words more than 2 letters\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens]  # lemmatize them\n",
    "    tokens = [t for t in tokens if t not in stopwords] # removing the stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_tokenized = []\n",
    "negative_tokenized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now I want to create an index for each of my words, so that each word will have its own index in the final data vector.\n",
    "word_index_map = {} # map words to indices\n",
    "current_index = 0 # it will increase whenever I see a new word.\n",
    "\n",
    "for review in positive_reviews:\n",
    "    tokens = my_tokenizer(review.text) # tokenizing the words from a given review. '.text' converts the corpus to a string\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in negative_reviews:\n",
    "    tokens = my_tokenizer(review.text) # tokenizing the words from a given review. '.text' converts the corpus to a string\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['purchased',\n",
       " 'this',\n",
       " 'unit',\n",
       " 'due',\n",
       " 'frequent',\n",
       " 'blackout',\n",
       " 'power',\n",
       " 'supply',\n",
       " 'bad',\n",
       " 'run',\n",
       " 'cable',\n",
       " 'modem',\n",
       " 'router',\n",
       " 'lcd',\n",
       " 'monitor',\n",
       " 'minute',\n",
       " 'this',\n",
       " 'time',\n",
       " 'save',\n",
       " 'shut',\n",
       " 'equally',\n",
       " 'electronics',\n",
       " 'receiving',\n",
       " 'clean',\n",
       " 'power',\n",
       " 'feel',\n",
       " 'this',\n",
       " 'investment',\n",
       " 'minor',\n",
       " 'compared',\n",
       " 'loss',\n",
       " 'valuable',\n",
       " 'data',\n",
       " 'failure',\n",
       " 'equipment',\n",
       " 'due',\n",
       " 'power',\n",
       " 'spike',\n",
       " 'irregular',\n",
       " 'power',\n",
       " 'supply',\n",
       " 'amazon',\n",
       " 'business',\n",
       " 'day']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tokenized[0] # tokens for the 1st review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # our vocabulary size + 1 (for the label)\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t] # get the index from the word_index_map\n",
    "        x[i] += 1  # counting the number of time a given token (word) has occurred and placing in by index in the x-array\n",
    "    x = x / x.sum() # taking the proportion\n",
    "    x[-1] = label # last place in the x-array is the label value\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)  # creating the xy data\n",
    "    data[i, :] = xy  # creating the terms-documents matrix\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i, :] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02272727,  0.06818182,  0.02272727, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.        ,  0.        ,  0.08333333, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:3,]  # how the data (tdm) looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "X = data[:, :-1] # all rows and everything expect the last column\n",
    "Y = data[:, -1] # all rows and the last column\n",
    "\n",
    "Xtrain = X[:-100, ] # n-100 rows\n",
    "Ytrain = Y[:-100, ]\n",
    "Xtest = X[-100:, ] # last 100 rows\n",
    "Ytest = Y[-100:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Rate:  0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Rate: \", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can look at the weights that each word has, to see if that word has positive or negative sentiment.\n",
    "# So, we are only interested to see the weghts which are far away from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11091"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excellent 1.37901783019\n",
      "comfortable 0.616864182857\n",
      "home 0.524906543303\n",
      "pro 0.501658861835\n",
      "support -0.838216132451\n",
      "returned -0.801154845597\n",
      "buy -0.808404552766\n",
      "customer -0.656858883524\n",
      "quality 1.51424312473\n",
      "recommend 0.669441306869\n",
      "picture 0.554290487222\n",
      "paper 0.581735867138\n",
      "refund -0.592400150479\n",
      "bad -0.778819168452\n",
      "time -0.595275432258\n",
      "little 0.873519580721\n",
      "unit -0.741762453688\n",
      "waste -0.947856210098\n",
      "then -1.09319438347\n",
      "month -0.718469318886\n",
      "item -0.968374402213\n",
      "price 2.80746360336\n",
      "using 0.65710622088\n",
      "sound 1.04919740495\n",
      "pretty 0.770956716708\n",
      "warranty -0.618821051962\n",
      "expected 0.557377790438\n",
      "speaker 0.946786896444\n",
      "cable 0.621942760353\n",
      "wa -1.56327408287\n",
      "you 1.023016148\n",
      "return -1.19354366257\n",
      "video 0.634326414007\n",
      "week -0.745043401469\n",
      "space 0.638827835221\n",
      "easy 1.76637483035\n",
      "'ve 0.800972810874\n",
      "money -0.989810580724\n",
      "n't -1.80723776261\n",
      "lot 0.677668764814\n",
      "fast 0.915560219336\n",
      "try -0.693867551178\n",
      "ha 0.872442812886\n",
      "bit 0.619292094803\n",
      "doe -1.18853213168\n",
      "happy 0.541922097699\n",
      "junk -0.515878107438\n",
      "highly 0.975759590213\n",
      "poor -0.787081156258\n",
      "tried -0.796535705563\n",
      "laptop 0.503025446444\n",
      "company -0.551804207513\n",
      "love 1.17702853374\n",
      "memory 0.928977813323\n",
      "perfect 1.03280187219\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "for word, index in word_index_map.items():\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)\n",
    "\n",
    "# More postive : Positive Words\n",
    "# More negative: Negative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
