{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Say our function is J = w^2, were J is an objetive function and w is the weights.\n",
    "# We want to find a value w which makes J(w) a global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "12.8\n",
      "10.24\n",
      "8.192\n",
      "6.5536\n",
      "5.24288\n",
      "4.194304000000001\n",
      "3.3554432000000007\n",
      "2.6843545600000005\n",
      "2.1474836480000006\n",
      "1.7179869184000005\n",
      "1.3743895347200004\n",
      "1.0995116277760002\n",
      "0.8796093022208001\n",
      "0.7036874417766401\n",
      "0.562949953421312\n",
      "0.45035996273704965\n",
      "0.3602879701896397\n",
      "0.28823037615171176\n",
      "0.23058430092136942\n",
      "0.18446744073709553\n",
      "0.14757395258967643\n",
      "0.11805916207174114\n",
      "0.09444732965739291\n",
      "0.07555786372591433\n",
      "0.06044629098073147\n",
      "0.048357032784585176\n",
      "0.03868562622766814\n",
      "0.030948500982134513\n",
      "0.02475880078570761\n",
      "0.01980704062856609\n",
      "0.015845632502852872\n",
      "0.012676506002282298\n",
      "0.01014120480182584\n",
      "0.008112963841460671\n",
      "0.006490371073168537\n",
      "0.00519229685853483\n",
      "0.004153837486827864\n",
      "0.0033230699894622913\n",
      "0.002658455991569833\n",
      "0.002126764793255866\n",
      "0.001701411834604693\n",
      "0.0013611294676837543\n",
      "0.0010889035741470034\n",
      "0.0008711228593176028\n",
      "0.0006968982874540822\n",
      "0.0005575186299632657\n",
      "0.00044601490397061256\n",
      "0.00035681192317649007\n",
      "0.00028544953854119207\n",
      "0.00022835963083295366\n",
      "0.00018268770466636292\n",
      "0.00014615016373309035\n",
      "0.00011692013098647228\n",
      "9.353610478917782e-05\n",
      "7.482888383134226e-05\n",
      "5.9863107065073806e-05\n",
      "4.7890485652059045e-05\n",
      "3.8312388521647236e-05\n",
      "3.064991081731779e-05\n",
      "2.4519928653854235e-05\n",
      "1.961594292308339e-05\n",
      "1.569275433846671e-05\n",
      "1.2554203470773367e-05\n",
      "1.0043362776618694e-05\n",
      "8.034690221294956e-06\n",
      "6.427752177035964e-06\n",
      "5.142201741628771e-06\n",
      "4.113761393303017e-06\n",
      "3.2910091146424137e-06\n",
      "2.632807291713931e-06\n",
      "2.106245833371145e-06\n",
      "1.6849966666969158e-06\n",
      "1.3479973333575326e-06\n",
      "1.0783978666860262e-06\n",
      "8.62718293348821e-07\n",
      "6.901746346790568e-07\n",
      "5.521397077432454e-07\n",
      "4.417117661945963e-07\n",
      "3.53369412955677e-07\n",
      "2.8269553036454164e-07\n",
      "2.2615642429163332e-07\n",
      "1.8092513943330665e-07\n",
      "1.4474011154664533e-07\n",
      "1.1579208923731627e-07\n",
      "9.263367138985301e-08\n",
      "7.410693711188241e-08\n",
      "5.9285549689505926e-08\n",
      "4.7428439751604744e-08\n",
      "3.794275180128379e-08\n",
      "3.0354201441027036e-08\n",
      "2.428336115282163e-08\n",
      "1.9426688922257304e-08\n",
      "1.5541351137805844e-08\n",
      "1.2433080910244675e-08\n",
      "9.946464728195741e-09\n",
      "7.957171782556592e-09\n",
      "6.365737426045273e-09\n",
      "5.092589940836219e-09\n",
      "4.0740719526689756e-09\n"
     ]
    }
   ],
   "source": [
    "w = 20 # we randomly choose a weight initially\n",
    "lr = 0.1 # say is the learning rate\n",
    "# Note 2w is the gradient of the function w^2 which is the slope or the 1st derivative.\n",
    "# Always think that you are coming down this parabolic curve and from somewhere above and trying to reach the minimum\n",
    "for i in range(100):\n",
    "    w = w - lr*2*w\n",
    "    print(w)\n",
    "# i.e. by moving slowly in the direction of the gradient of a function, we get closer and closer to the minimum of the function.\n",
    "# Over, here we take about 100 steps to reach there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
