{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Facial Expression Recognition.\n",
    "# The Data : https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Data\n",
    "\n",
    "Each image sample is 48x48 = 2304 dimensions  \n",
    "No Color  \n",
    "If we had color it would be 3x48x48 = 6912 dimensions  (There are 3 color channels Red, Green, and Blue)  \n",
    "With Logistic Regression and basic neural networks , we'll use a flat 2304 vector i.e. we won't work with 48x48 matrix.\n",
    "i.e. [-row1 -- row2 -- row3 -...] is (1 - 2304) elements in the vector which also means that we treat each pixel individually and ignore the spatial relationships i.e. 47th pixel is next to 48th pixel and so on... we just consider each individual pixel intensity.  \n",
    "\n",
    "In the Convolutional Neural Network we will use 48x48 matrix, i.e. we'll keep the original image shape.\n",
    "\n",
    "Another pre-processing we do is to normalize the data.  \n",
    "a) Images have pixel intensities 0..255 (i.e. 8 bit integers have 2^8 = 256 different possible values)  \n",
    "b) We want to normalize these to be from 0...1  \n",
    "c) It could be done by z = (x - mean)/stddev but in this case as the pixel value are all positive, we can just divide by the max. The reason why we need our values to be normalized as this is where the functions used in the neural network are most active i.e. sigmoid or tanh are most active i.e. steeper slope in between -1 and + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges we face\n",
    "a) Correct Learning Rate : Too high will the cost will explode and will result in NaN. Too low will result in slow convergence  \n",
    "b) Correct Regularization : Too high, makes the weight(w) too small and ignores the actual pattern ; Too low, no effect and the cost may still explode and become not a number.  \n",
    "c) How many epochs to use : Stop too early, not at minumum error. Stop too late , no effect on error, takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(balance_ones = True):\n",
    "    # images are 48x48 = 2304 size vectors\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(\"fer2013.csv\"):\n",
    "        if first:\n",
    "            first = False  # excluding the labels\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))  # this is the emotion level\n",
    "            X.append([int(p) for p in row[1].split()]) # the pixels are 2304 sized vectors which we are spliting here.\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X, Y =  getData(balance_ones=False)\n",
    "    \n",
    "    while True:\n",
    "        for i in range(7):\n",
    "            x, y = X[Y==i], Y[Y==i] # collecting all the images of the same kind\n",
    "            N = len(y)\n",
    "            j = np.random.choice(N) # randomly picking one image from the above lot.\n",
    "            plt.imshow(x[j].reshape(48, 48), cmap=\"gray\")\n",
    "            plt.title(label_map[y[j]])\n",
    "            plt.show()\n",
    "        prompt = input(\"Quit? Enter Y: \\n\")\n",
    "        if prompt == 'Y':\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
